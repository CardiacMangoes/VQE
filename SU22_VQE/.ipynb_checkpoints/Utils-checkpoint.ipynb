{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9d0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #operating system module for file IO\n",
    "import csv #csv module for spreadsheets\n",
    "\n",
    "import itertools #tools for iterating data\n",
    "\n",
    "import pandas as pd #database module\n",
    "import hashlib #consistent hashing for persistence\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pylab\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import figure\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import Aer\n",
    "from qiskit.opflow import X, Z, Y, I\n",
    "from qiskit.opflow.primitive_ops import PauliOp, PauliSumOp\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.algorithms import VQE, NumPyMinimumEigensolver\n",
    "from qiskit.circuit.library import TwoLocal, QAOAAnsatz\n",
    "\n",
    "from qiskit.algorithms.optimizers import ADAM, CG, COBYLA, L_BFGS_B, GradientDescent, NELDER_MEAD, \\\n",
    "                                            NFT, POWELL, SLSQP, SPSA, TNC\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{:0.3f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0292e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets up optimizers\n",
    "all_optimizers = [ADAM, CG, COBYLA, L_BFGS_B, GradientDescent, NELDER_MEAD, NFT, POWELL, SLSQP, SPSA, TNC]\n",
    "\n",
    "def setOptimizers(optimizers, max_iters):\n",
    "    all_optimizers = [ADAM, CG, COBYLA, L_BFGS_B, GradientDescent, \\\n",
    "                  NELDER_MEAD, NFT, POWELL, SLSQP, SPSA, TNC]\n",
    "    \n",
    "    bool_optimizers = [o in optimizers for o in all_optimizers]\n",
    "    \n",
    "    for i, optimizer in enumerate(all_optimizers):\n",
    "        if bool_optimizers[i]:\n",
    "            print(f\"\\x1b[32m{optimizer.__name__:15} ON\")\n",
    "        else: \n",
    "            print(f\"\\x1b[31m{optimizer.__name__:15} OFF\")\n",
    "            \n",
    "    optimizers = [o(maxiter=max_iters) for o in optimizers]\n",
    "        \n",
    "    return optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b6fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds a Pauli term by defining which pauli you want at what ndx and the size of the term\n",
    "def buildMonomial(pauli, ndx, size):\n",
    "    result = pauli if ndx == 0 else I\n",
    "    for i in range(1, size):\n",
    "        result ^= pauli if i == ndx else I\n",
    "    return result\n",
    "\n",
    "def buildTerm(size, pauli, coeff = 1.0):\n",
    "    result = pauli.get(0) or I\n",
    "    for i in range(1, size):\n",
    "        result ^= pauli.get(i) or I\n",
    "    return result * coeff\n",
    "    \n",
    "#converts Coupling Matrix -> PauliSumOp\n",
    "def buildHamiltonian(coupling_mat):\n",
    "    result = None\n",
    "    paulis = [X, Y, Z]\n",
    "    size = len(coupling_mat) // 3\n",
    "    \n",
    "    dim = len(coupling_mat.shape)\n",
    "    num_entries = np.prod(coupling_mat.shape)\n",
    "    \n",
    "    for i in range(num_entries):\n",
    "        f = lambda i,j : i // ((size*3)**j)\n",
    "        loc = tuple([(f(i,j) % (size*3)) for j in range(dim)])\n",
    "        \n",
    "        if coupling_mat[loc] != 0 and tuple(np.sort(loc)) == loc:\n",
    "            pauli_map = [paulis[aisle // size] for aisle in loc]\n",
    "            ndx_map = [aisle % size for aisle in loc]\n",
    "            ndx_pauli = dict(zip(ndx_map, pauli_map))\n",
    "            term = buildTerm(size, ndx_pauli, coupling_mat[loc])\n",
    "            result = result + term if result else term\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47e67048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for Coupling Matrix to make some things easier\n",
    "# Values are not split across diagonal\n",
    "class CouplingMatrix:\n",
    "    \n",
    "    def __init__(self, N, I_coeff = 0):\n",
    "        self.qubits = N\n",
    "        self.size = 3 * N\n",
    "        self.matrix = np.zeros((self.size, self.size), dtype=float)\n",
    "        self.I_coeff = I_coeff\n",
    "        self.set_submatrices()\n",
    "        self.constant = 0\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.matrix[key] = value\n",
    "        self.matrix[key[::-1]] = value\n",
    "        self.set_submatrices()\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.matrix[key]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.matrix.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.matrix.__str__()\n",
    "    \n",
    "    def getHamiltonian(self):\n",
    "        hamiltonian = buildHamiltonian(self.matrix)\n",
    "        if hamiltonian:\n",
    "            if self.I_coeff:\n",
    "                return hamiltonian + buildMonomial(I, 0, self.qubits) * self.I_coeff\n",
    "            else:\n",
    "                return hamiltonian\n",
    "    \n",
    "    def set_submatrices(self):\n",
    "        self.X = self.matrix[:self.qubits,:self.qubits]\n",
    "        self.Y = self.matrix[self.qubits:2*self.qubits,self.qubits:2*self.qubits]\n",
    "        self.Z = self.matrix[2*self.qubits:,2*self.qubits:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0aabe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds Schwinger Model Coupling Matrices\n",
    "def make_schwinger(N, H_E_coeff, H_M_coeff, H_I_coeff, theta = 0, mixer_type = 'XY'):\n",
    "    assert N >= 2, \"N has to be greater than or equal to 2\"\n",
    "    assert N <= 22, \"N can be no greater than 22\"\n",
    "    assert N % 2 == 0, \"N must be even\"\n",
    "    assert mixer_type in {'X', 'Y', 'XY'}, \"mixer_type must be 'X', 'Y', or 'XY'\"\n",
    "    \n",
    "    #Constant\n",
    "    I_coeff = (1/4) * ((N-1) * (theta/np.pi)**2 + np.ceil((N-1)/2.0) * (1 + 2*(theta/np.pi)) + ((N*(N-1))/2)) * H_E_coeff\n",
    "\n",
    "    mixer_coupling = CouplingMatrix(N)    \n",
    "    target_coupling = CouplingMatrix(N, I_coeff)\n",
    "\n",
    "    #H_E\n",
    "    for j in range(N-1):\n",
    "        for k in range(j):\n",
    "            target_coupling[j + 2*N, k + 2*N] += (N - j - 1)/2.0 * H_E_coeff\n",
    "\n",
    "    for j in range(N):\n",
    "        target_coupling[j + 2*N,j + 2*N] += (1/2.0) * ((theta/np.pi) * (N-j-1) + (np.ceil((N - j - 1)/2) - ((N*j)%2) )) * H_E_coeff\n",
    "\n",
    "    #H_M\n",
    "    for i in range(N):\n",
    "        target_coupling[i + 2*N,i + 2*N] += ((-1) ** i) * H_M_coeff\n",
    "\n",
    "    #H_I\n",
    "    for i in range(N-1):\n",
    "        if mixer_type in {'XY', 'X'}:\n",
    "            mixer_coupling[i,i + 1] += H_I_coeff\n",
    "        if mixer_type in {'XY', 'Y'}:  \n",
    "            mixer_coupling[i + N,i + 1 + N] += H_I_coeff\n",
    "            \n",
    "    target_ham = target_coupling.getHamiltonian()\n",
    "    mixer_ham = mixer_coupling.getHamiltonian()\n",
    "        \n",
    "    return target_ham, mixer_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2cc302",
   "metadata": {},
   "source": [
    "# Rendering Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccbcb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_coeff(ham):\n",
    "    if type(ham) == PauliOp:\n",
    "        min_coeff = abs(ham.coeff)\n",
    "    else:\n",
    "        min_coeff = min(abs(ham.coeffs))\n",
    "    return min_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48974cdb",
   "metadata": {},
   "source": [
    "# File IO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c93406",
   "metadata": {},
   "source": [
    "# Find Dimensionless Energy\n",
    "\n",
    "Given the first three eigenvalues of the Schwinger Model\n",
    "$$\\omega_0, \\omega_\\_, \\omega_+$$\n",
    "\n",
    "We find the dimensionless Eigenvalues\n",
    "\n",
    "$$\\begin{align}\n",
    "    f_0 &= \\frac{\\omega_0}{2Nx} \\\\\n",
    "    f_\\_ &=  \\frac{\\omega_\\_ - \\omega_0}{2\\sqrt(x)} - 2\\frac{m}{g} \\\\\n",
    "    f_+ &= \\frac{\\omega_+ - \\omega_0}{2\\sqrt(x)} - 2\\frac{m}{g}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6befd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the lowest two eigenvalues, w0 and w1\n",
    "def findDimensionlessEigen(x, N, m):\n",
    "    N = int(N)\n",
    "    m = m\n",
    "    target_coupling, mixer_coupling = make_schwinger(N, 1, np.sqrt(x) / 2 * m, x/2.0)\n",
    "\n",
    "    mixer_hamiltonian = mixer_coupling.getHamiltonian()\n",
    "    target_hamiltonian = target_coupling.getHamiltonian()\n",
    "\n",
    "    complete_hamiltonian = mixer_hamiltonian + target_hamiltonian\n",
    "\n",
    "    sparse_matrix_ham = complete_hamiltonian.to_spmatrix()\n",
    "    eigenvalues = np.sort(scipy.sparse.linalg.eigsh(sparse_matrix_ham, return_eigenvectors=False, which = 'SA', k = 3))\n",
    "    \n",
    "    w0, w1, w2 = eigenvalues[:3]\n",
    "    f0, f1, f2 = w0/(2*N*x), ((w1-w0)/(2*np.sqrt(x))) - 2*m, ((w2-w0)/(2*np.sqrt(x))) - 2*m\n",
    "    \n",
    "    return f0, f1, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e08cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionless_eigv(N, x, m):\n",
    "    N = int(N)\n",
    "    target_coupling, mixer_coupling = make_schwinger(N, 1, np.sqrt(x) / 2 * m, x/2.0)\n",
    "\n",
    "    mixer_hamiltonian = mixer_coupling.getHamiltonian()\n",
    "    target_hamiltonian = target_coupling.getHamiltonian()\n",
    "\n",
    "    complete_hamiltonian = mixer_hamiltonian + target_hamiltonian\n",
    "\n",
    "    matrix_ham = complete_hamiltonian.to_matrix(massive = True)\n",
    "    \n",
    "    return np.sort(np.linalg.eigvalsh(matrix_ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e05f54",
   "metadata": {},
   "source": [
    "# Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5734917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_extrapolated_data(x_data, y_data, z_data, extrap_range, extrap_axis, poly_size = 2, get_intercept = False):\n",
    "    \n",
    "    assert extrap_axis == 'y' or extrap_axis =='x'\n",
    "    \n",
    "    x_data, y_data = x_data[0], y_data.T[0]\n",
    "    \n",
    "    if extrap_axis == 'y':\n",
    "        x_range, y_range = len(x_data), len(extrap_range)\n",
    "        x_data_extrap, y_data_extrap = np.meshgrid(x_data, extrap_range)\n",
    "        dep_axis = np.array(y_data)\n",
    "    else:\n",
    "        x_range, y_range = len(y_data), len(extrap_range)\n",
    "        x_data_extrap, y_data_extrap = np.meshgrid(extrap_range, y_data)\n",
    "        dep_axis = np.array(x_data)\n",
    "\n",
    "    poly_data = [np.zeros([x_range, y_range], dtype=float) for _ in range(poly_size)]\n",
    "    \n",
    "    if extrap_axis == 'y':\n",
    "        poly_intercepts = np.zeros([poly_size, len(z_data)])\n",
    "    \n",
    "    for i in range(len(z_data)):\n",
    "        indep_axis = np.array(z_data[i])\n",
    "        intercept = []\n",
    "        for p in range(poly_size):\n",
    "            coeffs = np.polyfit(dep_axis, indep_axis, p + 1)\n",
    "            poly_intercepts[p, i] = coeffs[-1]\n",
    "            poly_data[p][i] = np.poly1d(coeffs)(extrap_range)\n",
    "            \n",
    "    if extrap_axis == 'y':\n",
    "        poly_data = [poly.T for poly in poly_data]\n",
    "    \n",
    "    if get_intercept:\n",
    "        return x_data_extrap, y_data_extrap, poly_data, poly_intercepts\n",
    "    return x_data_extrap, y_data_extrap, poly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9657d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_iterable(inp):\n",
    "    '''\n",
    "    Checks whether an input is iterable\n",
    "    '''\n",
    "    try:\n",
    "        iterator = iter(inp)\n",
    "    except TypeError:\n",
    "        return False\n",
    "    else:\n",
    "        return type(inp) != str\n",
    "\n",
    "def check_float(num):\n",
    "    '''\n",
    "    Checks whether a string can be interpreted as an integer or float\n",
    "    '''\n",
    "    assert type(num) == str, \"Only checks strings\"\n",
    "    try:\n",
    "        fnum = float(num)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaa55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_iterable(t):\n",
    "    '''\n",
    "    hashes an iterable\n",
    "    '''\n",
    "    m = hashlib.sha256()\n",
    "    for s in t:\n",
    "        m.update(bytes(str(s).encode('utf-8')))\n",
    "    fn = m.hexdigest()\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_range(xrr = (0,1), yrr = (0,1)):\n",
    "    size = renders[list(renders)[0]][0].shape\n",
    "    xrr = (int(np.ceil(xrr[0] * size[0])),int(np.ceil(xrr[1] * size[0])))\n",
    "    yrr = (int(np.ceil(yrr[0] * size[1])), int(np.ceil(yrr[1] * size[1])))\n",
    "    return xrr, yrr\n",
    "\n",
    "def dict_cartesian_product(dic):\n",
    "    '''\n",
    "    Makes a cartesian product of a dictionary that has lists for values\n",
    "    '''\n",
    "    keys = dic.keys()\n",
    "    values_cp = itertools.product(*dic.values())\n",
    "    return list(dict(zip(keys, values)) for values in values_cp)\n",
    "\n",
    "    # df = pd.DataFrame({'a': [[3,4,6]], 'b': [[1]]})\n",
    "    # for i in df.columns:\n",
    "    #     df = df.explode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandscapeDataFrame:\n",
    "    models = ['schwinger']\n",
    "    reprs = {'schwinger' : ['standard', 'dimensionless']}\n",
    "    \n",
    "    parameters = {'_all_': ['hash', 'p', 'quality'],\n",
    "                  'schwinger': \n",
    "                  {'_general_': ['N', 'H_E', 'H_M', 'H_I', 'theta', 'mixer_type'],\n",
    "                   'standard': ['g', 'm', 'a'],\n",
    "                   'dimensionless': ['m/g', 'x']\n",
    "                  }\n",
    "                 }\n",
    "    \n",
    "    parameter_types = {'schwinger':\n",
    "                       {'N': int, 'theta': float, 'p':int, 'mixer_type': str, 'g': float, 'm': float, 'a': float, 'm/g': float, 'x': float}\n",
    "                      }\n",
    "    \n",
    "    coeff_funcs = {'schwinger': \n",
    "                  {'standard': lambda params: {'H_E': (params['g']**2)*params['a']/2,'H_M': params['m']/2,'H_I': 1/(4*params['a'])},\n",
    "                   'dimensionless': lambda params: {'H_E': 1,'H_M': np.sqrt(params['x'])/2*params['m/g'],'H_I': params['x']/2}\n",
    "                  }\n",
    "                 }\n",
    "    \n",
    "    def __init__(self, model, rep):\n",
    "        assert model in self.models, \"Not a specified Model\"\n",
    "        assert rep in self.reprs[model], f\"Not a represenetation for the {model} model\"\n",
    "        self.model = model.lower()\n",
    "        self.rep = rep.lower()\n",
    "        self.init_dir()\n",
    "        \n",
    "    def render_landscapes(self, param_ranges, p, quality):\n",
    "        param_table = dict_cartesian_product(param_ranges)\n",
    "        for param in param_table:\n",
    "            self.render_landscape(param, p, quality)\n",
    "    \n",
    "    def render_landscape(self, params, p, quality):\n",
    "        print(*[f\"{key}: {str(params[key])},\" for key in params])\n",
    "        \n",
    "        for key in params:\n",
    "            type_ = self.parameter_types[self.model][key]\n",
    "            value = type_(params[key])\n",
    "            params[key] = value\n",
    "        \n",
    "        coeffs = self.coeff_funcs[self.model][self.rep](params)\n",
    "        params.update(coeffs)\n",
    "        \n",
    "        general_params = [params[param] for param in np.sort(self.parameters[self.model]['_general_'])]\n",
    "        params['hash'] = hash_iterable(general_params)\n",
    "        params['p']  = p\n",
    "        params['quality']  = quality\n",
    "        self.load_landscape(params)\n",
    "\n",
    "    def init_dir(self):\n",
    "        if not os.path.exists(\"landscape_data\"): # check if main directory exists\n",
    "            os.makedirs(\"landscape_data\")\n",
    "        if not os.path.exists(f\"landscape_data/{self.model}\"): # check if model directory exists\n",
    "            os.makedirs(f\"landscape_data/{self.model}\")\n",
    "        if not os.path.exists(f\"landscape_data/{self.model}/data\"): # check if model data directory exists\n",
    "            os.makedirs(f\"landscape_data/{self.model}/data\")\n",
    "        for rep in self.parameters[self.model]:\n",
    "            if not os.path.exists(f\"landscape_data/{self.model}/{rep}.csv\"): # check if each repr directory for model exists\n",
    "                fieldnames = self.parameters[self.model][rep].copy()\n",
    "                if rep != '_general_':\n",
    "                    fieldnames.extend(self.parameters[self.model]['_general_'])\n",
    "                fieldnames.extend(self.parameters['_all_'])\n",
    "                df = pd.DataFrame(columns=fieldnames)\n",
    "                df.to_csv(f\"landscape_data/{self.model}/{rep}.csv\", index=False)\n",
    "\n",
    "    def save_file(self, landscape, params):\n",
    "        f = open(f\"landscape_data/{self.model}/data/{params['hash']}.npz\", 'wb')\n",
    "        np.savez(f, **landscape)\n",
    "        f.close()\n",
    "        \n",
    "        self.update_csv('_general_', params)\n",
    "        self.update_csv(self.rep, params)\n",
    "        \n",
    "    def update_csv(self, rep, params):\n",
    "        df = pd.read_csv(f\"landscape_data/{self.model}/{rep}.csv\") # representation data frame\n",
    "        row = df[df['hash'] == params['hash']] # data frame row with params\n",
    "\n",
    "        if row.shape[0] > 0:\n",
    "            df.at[row.index[0],'quality'] = params['quality']\n",
    "            df.at[row.index[0],'p'] = params['p']\n",
    "        else:\n",
    "            df = df.append(params, ignore_index=True)\n",
    "            \n",
    "        df.to_csv(f\"landscape_data/{self.model}/{rep}.csv\", index=False)\n",
    "    \n",
    "    def get_hashes(self, params):\n",
    "        df = pd.read_csv(f\"landscape_data/{self.model}/{self.rep}.csv\")\n",
    "        hashes = []\n",
    "        for index, row in df.iterrows():\n",
    "            row = row.to_dict()\n",
    "            comparison = len({k: row[k] for k in params if k in row and params[k] == row[k]})\n",
    "            if comparison == len(params):\n",
    "                hashes.append(row.get('hash'))\n",
    "        if not hashes:\n",
    "            print('Parameterization does not exist')\n",
    "        return hashes\n",
    "        \n",
    "    def open_files(self, params):\n",
    "        contains_rep_params = all([params.get(p) for p in self.parameters[self.model][self.rep]])\n",
    "        landscapes = []\n",
    "        if contains_rep_params:\n",
    "            hashes = self.get_hashes(params)\n",
    "            for hash_ in hashes:\n",
    "                landscape = self.open_file(hash_)\n",
    "                landscapes.append(landscape)\n",
    "        return landscapes\n",
    "    \n",
    "    def open_file(self, hash_):\n",
    "        '''\n",
    "        Opens a single file from its hash name\n",
    "        '''\n",
    "        if hash_:\n",
    "            f = open(f\"landscape_data/{self.model}/data/{hash_}.npz\", 'rb')\n",
    "        else:\n",
    "            print(f\"{hash_}.npz does not exist\")\n",
    "        npzfile = np.load(f, allow_pickle=True)\n",
    "        landscape = dict(npzfile)\n",
    "        f.close()\n",
    "        return landscape\n",
    "        \n",
    "    def load_landscape(self,params):\n",
    "        if self.model == 'schwinger':\n",
    "            target, mixer = self.make_schwinger(params)\n",
    "        \n",
    "        df = pd.read_csv(f\"landscape_data/{self.model}/_general_.csv\") # _general_ data frame\n",
    "        row = df[df['hash'] == params['hash']] #_general_ data frame row with params\n",
    "        \n",
    "        # check if specific schwinger model parameters already exists\n",
    "        if row.shape[0] == 0: # there is not a row with these parameters\n",
    "            landscape = self.setup_calc_landscape(target, mixer, params) \n",
    "            self.save_file(landscape, params)\n",
    "        elif any(params['p'] > row['p']) or any(params['quality'] > row['quality']):\n",
    "            landscape = self.setup_calc_landscape(target, mixer, params)\n",
    "            self.save_file(landscape, params)\n",
    "        else: # there is a row with these parameters\n",
    "            print(f\"Already Rendered with p: {row['p'].iloc[0]}, Quality: {row['quality'].iloc[0]}\")\n",
    "            \n",
    "    def calc_landscape(self, gamma_range, beta_range, energy_f, p):\n",
    "        energy = np.zeros([len(gamma_range), len(beta_range)] * p)\n",
    "        ttl = energy.size\n",
    "        \n",
    "        counter = 1\n",
    "        start = time.time()\n",
    "        for i, e in np.ndenumerate(energy):\n",
    "            inputs = [i[r:r+2] for r in np.arange(0,p*2,2)]\n",
    "            b_args = [beta_range[r[1]] for r in inputs[::-1]]\n",
    "            g_args = [gamma_range[r[0]] for r in inputs[::-1]]\n",
    "            args =  b_args + g_args\n",
    "            energy[i] = energy_f(args)\n",
    "            proportion,  counter = counter / ttl * 100, counter + 1\n",
    "            print(f'{proportion:3.2f}% | time remaining: {(time.time() - start) * (100-proportion)/proportion :5.1f}s    ', end='\\r', flush = True)\n",
    "                \n",
    "        return energy\n",
    "\n",
    "    def setup_calc_landscape(self, target, mixer, params):\n",
    "        assert params.get('quality') is not None, \"Require resolution 'quality'\"\n",
    "        assert params.get('p') is not None, \"Require number of rounds 'p'\"\n",
    "        \n",
    "        p = params['p']\n",
    "        complete_ham = target + mixer\n",
    "        gamma_range, beta_range = self.landscape_domain(target, mixer, params)\n",
    "\n",
    "        ansatz = QAOAAnsatz(cost_operator = target, \n",
    "                            mixer_operator = mixer,\n",
    "                            reps = p,\n",
    "                            name = 'QAOA')\n",
    "        vqe = VQE(ansatz, quantum_instance=QuantumInstance(backend=Aer.get_backend('statevector_simulator'))) # 5 - 10 samples per point\n",
    "        \n",
    "        energy_eval = vqe.get_energy_evaluation(complete_ham)\n",
    "        calc_vqe_energy = lambda args: energy_eval(args)\n",
    "        \n",
    "        grnd_energy = NumPyMinimumEigensolver().compute_minimum_eigenvalue(operator=complete_ham).eigenvalue\n",
    "        \n",
    "        start = time.time()\n",
    "        energy = self.calc_landscape(gamma_range, beta_range, calc_vqe_energy, p)\n",
    "        print(f\"Rendered In: {time.time() - start : .2f}s\" + '\\t' * 20)\n",
    "        return {'gamma': gamma_range, 'beta': beta_range, 'energy': energy, 'grnd_energy': grnd_energy}\n",
    "    \n",
    "    def landscape_domain(self, target, mixer, params):\n",
    "        quality = 2 ** params['quality']\n",
    "        \n",
    "        min_gamma_coeff = find_min_coeff(target)\n",
    "        min_beta_coeff = find_min_coeff(mixer)\n",
    "        \n",
    "        gamma_range = np.linspace(0, (2/min_gamma_coeff)*np.pi, int(quality /(min_gamma_coeff)) + 1)\n",
    "        beta_range = np.linspace(0, (2/min_beta_coeff)*np.pi, int(quality /(min_beta_coeff)) + 1)\n",
    "        return gamma_range, beta_range\n",
    "        \n",
    "    def make_schwinger(self,params):\n",
    "        target, mixer = make_schwinger(N = params['N'], \n",
    "                                       H_E_coeff = params['H_E'],\n",
    "                                       H_M_coeff = params['H_M'],\n",
    "                                       H_I_coeff = params['H_I'],\n",
    "                                       theta = params['theta'], mixer_type = params['mixer_type'])\n",
    "        return target, mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f79da26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = [0,1]\n",
    "# b = [0,5,2]\n",
    "# p = 2\n",
    "# np.arange(0,p*2,2)\n",
    "\n",
    "# land = np.zeros([len(g), len(b)] * p)\n",
    "# counter = 0\n",
    "# for i, l in np.ndenumerate(land):\n",
    "#     counter+=1\n",
    "#     inputs = [i[r:r+2] for r in np.arange(0,p*2,2)]\n",
    "#     print(f\"{counter}: {inputs}\")\n",
    "#     g_args = [g[r[0]] for r in inputs[::-1]]\n",
    "#     b_args = [b[r[1]] for r in inputs[::-1]]\n",
    "#     print(f\"{g_args + b_args}\")\n",
    "#     print()\n",
    "#     land[i] = counter\n",
    "# land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110dc33a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H_E', 'H_I', 'H_M', 'N', 'mixer_type', 'theta'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754aa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b303d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
